import socket
import struct
import time
from datetime import datetime
import numpy as np
import cv2
from filterpy.kalman import UnscentedKalmanFilter, MerweScaledSigmaPoints

###################### WiFi Reception #############################
DEST_PORT = 4600  # must match sender port

def setup_socket(port=DEST_PORT):
    """Set up and return a non-blocking UDP socket bound to the given port."""
    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
    sock.bind(('', port))
    sock.setblocking(False)  # non-blocking mode for integration into main loop
    return sock

def receive_centroid(sock):
    """
    Attempts to receive a 5-byte UDP packet.
    Returns:
        (pi_id, cx, cy, timestamp) if valid;
        None if no data or if the packet is invalid.
    """
    try:
        data, addr = sock.recvfrom(1024)
        if len(data) == 5:
            pi_id = data[0]
            cx, cy = struct.unpack('!HH', data[1:5])
            timestamp = datetime.now().isoformat(timespec='microseconds')
            return pi_id, cx, cy, timestamp
        else:
            print(f"Received invalid packet length: {len(data)} from {addr}")
            return None
    except BlockingIOError:
        return None

############################ UKF and Dynamics ############################

# --- Load Calibration Data ---
# (The intrinsic and extrinsic files should be in your working directory)
intrinsics_left = np.load("intrinsic_white.npz")
K_left = intrinsics_left["camera_matrix"]
dist_left = intrinsics_left["dist_coeffs"]

intrinsics_right = np.load("intrinsic_black.npz")
K_right = intrinsics_right["camera_matrix"]
dist_right = intrinsics_right["dist_coeffs"]

extrinsics = np.load('stereo_extrinsics.npz')
R_side = extrinsics['R']      # rotation matrix for side camera
T_side = extrinsics['T']      # translation for side camera

# --- Measurement functions ---
def hx_floor(state):
    """
    Projects a 3D state from the floor camera's (world) coordinates
    to 2D pixel coordinates.
    """
    p = state[:3]
    X, Y, Z = p
    Z = max(Z, 1e-3)
    u = K_left[0, 0] * (X / Z) + K_left[0, 2]
    v = K_left[1, 1] * (Y / Z) + K_left[1, 2]
    return np.array([u, v])

def hx_side(state):
    """
    Transforms a 3D point from the world coordinate frame into the side camera frame
    and projects it to pixel coordinates.
    """
    p = state[:3]
    p_cam = R_side @ p + T_side.reshape(3)
    X, Y, Z = p_cam
    Z = max(Z, 1e-3)
    u = K_right[0, 0] * (X / Z) + K_right[0, 2]
    v = K_right[1, 1] * (Y / Z) + K_right[1, 2]
    return np.array([u, v])

R_meas = np.array([[9.0, 0],
                   [0, 4.0]])  # measurement noise covariance

# --- Dynamics ---
g = 9.81   # gravitational acceleration (m/s^2)
kv = 0.30  # drag coefficient for filtering updates

def fx(state, dt):
    """
    Process model for projectile dynamics with gravity and drag.
    State vector: [x, y, z, vx, vy, vz]
    """
    x, y, z, vx, vy, vz = state
    ax = -kv * vx
    ay = -kv * vy
    az = -kv * vz - g
    return np.array([x + vx * dt,
                     y + vy * dt,
                     z + vz * dt,
                     vx + ax * dt,
                     vy + ay * dt,
                     vz + az * dt])

def propagate_state_analytical(state, t, kv=0.67, g=9.81):
    """
    Analytically propagate the state over time t.
    Uses known solutions for a projectile with drag (x and y) and gravity (z).
    """
    x0, y0, z0, vx0, vy0, vz0 = state
    x = x0 + (vx0 / kv) * (1 - np.exp(-kv*t))
    vx = vx0 * np.exp(-kv*t)
    y = y0 + (vy0 / kv) * (1 - np.exp(-kv*t))
    vy = vy0 * np.exp(-kv*t)
    z = z0 + ((vz0 + g/kv) / kv) * (1 - np.exp(-kv*t)) - (g * t)/kv
    vz = (vz0 + g/kv) * np.exp(-kv*t) - g/kv
    return np.array([x, y, z, vx, vy, vz])

def time_to_target(x0, vx0, target, kv):
    """
    Solves for time t such that x(t) reaches target.
    Returns None if no valid solution exists.
    """
    arg = 1 - (kv * (target - x0)) / vx0
    if arg <= 0:
        return None
    return -np.log(arg) / kv

def predict_state_at_target(initial_state, target_x, kv=0.67, g=9.81):
    """
    Given an initial state, calculate the time to reach target_x and
    propagate the full state accordingly.
    
    Returns:
       predicted_state: state [x, y, z, vx, vy, vz] at target_x,
       t_target: time required.
    """
    x0 = initial_state[0]
    vx0 = initial_state[3]
    t_target = time_to_target(x0, vx0, target_x, kv)
    if t_target is None:
        print("Cannot reach the target x with the given initial conditions.")
        return None, None
    predicted_state = propagate_state_analytical(initial_state, t_target, kv, g)
    return predicted_state, t_target

# --- UKF Initialization ---
dim_x = 6  # state: [x, y, z, vx, vy, vz]
dim_z = 2  # measurement: [u, v]
points = MerweScaledSigmaPoints(n=dim_x, alpha=0.1, beta=2.0, kappa=0)
ukf = UnscentedKalmanFilter(dim_x=dim_x, dim_z=dim_z, dt=0.02, fx=fx, hx=hx_floor, points=points)
ukf.x = np.array([0.8, 0.0, 1.8, -9.5, 0.0, 0.0])  # initial guess (modify as needed)
ukf.P = np.eye(dim_x) * 1.0
ukf.Q = np.eye(dim_x) * 0.5
ukf.Q[1, 1] = 0.02
ukf.Q[2, 2] = 0.02
ukf.Q[3, 3] = 0.02

########################### Projection (Dartboard) Setup #############################

# Screen dimensions for the projector (in pixels)
SCREEN_WIDTH, SCREEN_HEIGHT = 1920, 1080

# Load and prepare dartboard image
dartboard = cv2.imread("target_large_bullseye.png", cv2.IMREAD_UNCHANGED)
DARTBOARD_SIZE = 435
dartboard = cv2.resize(dartboard, (DARTBOARD_SIZE, DARTBOARD_SIZE))
# Convert to RGBA for transparency processing (assumes dartboard has an alpha channel)
dartboard = cv2.cvtColor(dartboard, cv2.COLOR_BGRA2RGBA)

# --- Distortion Correction ---
image_width, image_height = 640, 640
rect = np.array([[0, 0],
                 [image_width, 0],
                 [0, image_height],
                 [image_width, image_height]], dtype=np.float32)
theta = 15  # tilt angle (degrees)
y_shift = 15  # vertical displacement
# Define a trapezoidal mapping for distortion correction
trapezoid = np.array([[20, y_shift],
                      [630, 0],
                      [10, image_height - y_shift],
                      [640, image_height]], dtype=np.float32)
H_distortion = cv2.getPerspectiveTransform(rect, trapezoid)
warped_dartboard = cv2.warpPerspective(dartboard, H_distortion, (image_width, image_height))
warped_height, warped_width = warped_dartboard.shape[:2]

# --- Position Prediction to Projector Coordinates ---
# Homography from real-world (in centimeters) to projector coordinates.
H_position = np.array([[ 1.07581897e+01,  1.18900969e+00,  9.48182841e+02],
                       [ 2.77725678e-01, -7.43562709e+00,  5.40503774e+02],
                       [ 4.55825948e-04,  9.93956939e-04,  1.00000000e+00]])

def real_to_projector(real_pos):
    """
    Convert a 2D position in real-world coordinates (in centimeters)
    to projector coordinates using H_position.
    """
    point = np.array([[[real_pos[0], real_pos[1]]]], dtype=np.float32)
    projected = cv2.perspectiveTransform(point, H_position)[0][0]
    return int(projected[0]), int(projected[1])

# Global predicted projector coordinates (to be updated by the measurement loop)
current_prediction = (0, 0)

def update_projector_prediction(real_x_cm, real_y_cm):
    """
    Given a predicted real-world (cm) position, update the global projector coordinates.
    """
    global current_prediction
    current_prediction = real_to_projector((real_x_cm, real_y_cm))

def draw_dartboard(center_pos):
    """
    Draws the dartboard image on a black screen at the given center position.
    """
    frame = np.zeros((SCREEN_HEIGHT, SCREEN_WIDTH, 3), dtype=np.uint8)
    # Center the warped dartboard
    x = center_pos[0] - warped_width // 2
    y = center_pos[1] - warped_height // 2
    if 0 <= x < SCREEN_WIDTH - warped_width and 0 <= y < SCREEN_HEIGHT - warped_height:
        roi = frame[y:y+warped_height, x:x+warped_width]
        alpha = warped_dartboard[:, :, 3] / 255.0
        for c in range(0, 3):
            roi[:, :, c] = (warped_dartboard[:, :, c] * alpha +
                            roi[:, :, c] * (1 - alpha)).astype(np.uint8)
    cv2.putText(frame, f"Prediction: {center_pos}", (20, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
    return frame

########################### Integrated Main Function #############################
def main():
    # --- Set up UDP socket and buffers ---
    sock = setup_socket()
    centroid_buffer = []
    camera_buffer = []
    timestamp_buffer = []
    start_time = None

    print("Collecting centroid measurements over ~0.265 secondsâ€¦")
    try:
        while True:
            result = receive_centroid(sock)
            if result:
                pi_id, cx, cy, ts_full = result
                print(f"[{ts_full}] Pi {pi_id} -> centroid_x = {cx}, centroid_y = {cy}")
                # Extract seconds (with microseconds) from timestamp string
                parts = ts_full.split(":")
                ts_val = float(parts[2])
                centroid_buffer.append([cx, cy])
                camera_buffer.append(pi_id)
                timestamp_buffer.append(ts_val)
                if start_time is None:
                    start_time = time.perf_counter()
            if start_time is not None and (time.perf_counter() - start_time) > 0.265:
                break
            time.sleep(0.003)  # reduce CPU usage
    except KeyboardInterrupt:
        print("Measurement loop interrupted.")
    finally:
        sock.close()

    if len(timestamp_buffer) == 0:
        print("No centroids received, aborting prediction.")
        return

    # --- Process buffered measurements with the UKF ---
    prev_ts = timestamp_buffer[0]
    for i in range(len(timestamp_buffer)):
        current_ts = timestamp_buffer[i]
        dt = current_ts - prev_ts if i > 0 else 0.0
        prev_ts = current_ts
        ukf.predict(dt)
        # Keep covariance symmetric and stable
        ukf.P = (ukf.P + ukf.P.T) / 2 + np.eye(dim_x)*1e-6
        meas = np.array(centroid_buffer[i])
        if camera_buffer[i] == 2:
            ukf.update(meas, R=R_meas, hx=hx_floor)
        elif camera_buffer[i] == 1:
            ukf.update(meas, R=R_meas, hx=hx_side)
        ukf.P = (ukf.P + ukf.P.T) / 2 + np.eye(dim_x)*1e-6

    # --- Use the final UKF state to predict landing state ---
    target_x = -2.10  # desired target x position in meters
    predicted_state, t_target = predict_state_at_target(ukf.x, target_x, kv=0.67, g=9.81)
    if predicted_state is None:
        print("Prediction failed.")
        return

    # For display we want a 2D (x,y) prediction.
    # (Adjust the conversion factors as needed.)
    # Here we assume predicted_state is in meters; convert to centimeters.
    pred_x_cm = predicted_state[0] * 100
    pred_y_cm = predicted_state[1] * 100
    print("Time to reach x = {:.2f} m: {:.4f} s".format(target_x, t_target))
    print("Predicted state (meters):")
    print(" x = {:.4f}, y = {:.4f}, z = {:.4f}".format(predicted_state[0],
                                                         predicted_state[1],
                                                         predicted_state[2]))
    print("Predicted state (cm) for display:")
    print(" x = {:.2f} cm, y = {:.2f} cm".format(pred_x_cm, pred_y_cm))

    # --- Update the projector coordinates with the predicted real-world position ---
    update_projector_prediction(pred_x_cm, pred_y_cm)

    # --- Set up OpenCV window in fullscreen ---
    cv2.namedWindow("Projection", cv2.WND_PROP_FULLSCREEN)
    cv2.setWindowProperty("Projection", cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

    print("Starting projection display. Press ESC to exit.")
    # --- Main display loop ---
    while True:
        # In a continuously running version you might update the UKF with new data
        # and recalc the prediction. Here we simply display the computed prediction.
        frame = draw_dartboard(current_prediction)
        # OpenCV expects BGR images for imshow
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)
        cv2.imshow("Projection", frame_bgr)
        key = cv2.waitKey(1)
        if key == 27:  # ESC key to exit
            break

    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
